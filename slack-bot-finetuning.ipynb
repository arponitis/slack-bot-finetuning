{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzrSngeIPEcbGZQzXKg2ao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arponitis/slack-bot-finetuning/blob/main/slack-bot-finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a58c7f4"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "761fe09d"
      },
      "source": [
        "!pip install -q transformers peft datasets bitsandbytes accelerate"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fbc51d3"
      },
      "source": [
        "## 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7686f356"
      },
      "source": [
        "import json\n",
        "import re\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0d13bf5"
      },
      "source": [
        "## 3. Load & Preprocess Chat Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f171296e",
        "outputId": "33bc7c06-e80f-4aca-dc51-75a3ac1ccb5f"
      },
      "source": [
        "# Example: Slack JSON export (replace 'slack_export.json' with your file)\n",
        "# Slack/Teams exports usually look like:\n",
        "# [\n",
        "#   {\"user\": \"Alice\", \"text\": \"Hello Bob\", \"ts\": \"1680000000.000000\"},\n",
        "#   {\"user\": \"Bob\", \"text\": \"Hey Alice!\", \"ts\": \"1680000001.000000\"}\n",
        "# ]\n",
        "#\n",
        "# Upload your export file to Colab: Runtime → Files → Upload\n",
        "CHAT_FILE = \"/content/slack_export.json\"  # change this\n",
        "\n",
        "with open(CHAT_FILE, \"r\") as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "# Remove system messages and empty texts\n",
        "cleaned = [\n",
        "    msg for msg in raw_data\n",
        "    if msg.get(\"text\") and not msg[\"text\"].startswith(\"<@\") and \"joined\" not in msg[\"text\"].lower()\n",
        "]\n",
        "\n",
        "# Convert into conversation turns (instruction → response)\n",
        "pairs = []\n",
        "for i in range(len(cleaned) - 1):\n",
        "    current = cleaned[i]\n",
        "    nxt = cleaned[i + 1]\n",
        "    if current[\"user\"] != nxt[\"user\"]:  # only consecutive different speakers\n",
        "        instruction = f\"{current['user']}: {current['text']}\\n{nxt['user']}:\"\n",
        "        output = nxt[\"text\"]\n",
        "        pairs.append({\n",
        "            \"instruction\": \"Respond in the style of our team chat\",\n",
        "            \"input\": instruction,\n",
        "            \"output\": output\n",
        "        })\n",
        "\n",
        "print(f\"Prepared {len(pairs)} conversation pairs.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 810 conversation pairs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6366caa9"
      },
      "source": [
        "## 4. Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3134ea2f"
      },
      "source": [
        "dataset = Dataset.from_list(pairs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68a0d2b7"
      },
      "source": [
        "## 5. Tokenization Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "02336ce19a2b4fa18c03e7804e3df6b9",
            "d6d5e1e8df9a4af79128d41b8cb0c6b5",
            "bac4c3684281463a837055fb47e163cf",
            "f9f8fb2eab0a417396348df57f9da0ec",
            "f29e004627c040f497436cb9e88c26a8",
            "ba3ac39674284e27893d0330c2d40998",
            "f1d985f611a5431f9441082b78b45cc9",
            "b5135885fc3d4442a182f47f5eb2a201",
            "34e17b74b4e74083a0a5fb94a70960a6",
            "7cd954a9d7a1487da9bd1f315912ad47",
            "8180a89931ca4edea23965a376ae2f93",
            "de494844c63b4c7a81bc18750c650560",
            "3a8d920a3ba842a2838e11af324a0ff5",
            "5ebc6937dddf48ada06b714cdef63f66",
            "9e363c169eef4c36995a8d6843c2b30c",
            "0a6ed02e43b9484c902bef13b1d8b8ef",
            "45ab067304d34c0c9d85355533a74962",
            "a63e4cc06cd54437a0661635f1a05ab0",
            "dcef1c7cb0ec4230a3ed7f8ab3e9ba42",
            "6f2139e881414a8cb2edb3ad0844b212",
            "d94cc0ea330d468bb6e5dcea73b96375",
            "5cbd6c57ecc04aec93d8215307130cc7",
            "071e7073a8df4e858d8920ba0f3e40eb",
            "65405d504b33477c91a639dca37cf849",
            "e760c2ba76e446d280b0febcb721acc4",
            "756393e04a47426cb9d19d7cce68cd71",
            "a2c30d7a600b4cedb726606ecb65841b",
            "9340c5db7b184d7f81b226586b5272ee",
            "262c8ee7fcd944439727f8ab3f07b609",
            "d50f82cfe3d240789e0a8fb78fdaf109",
            "4008976a10314c48a92fd7c0fbe72862",
            "2355df4e17cf43e0a58a70f129ed5319",
            "63bb047f172b4e098181ed189aad7dad",
            "e20a93877fcf44aca8812aecdad1e33c",
            "b872cc782be14d419c09a6f89b05c835",
            "410501cbd0db48fdbe6f97c4ed6432aa",
            "abbbe5c44c3d442389fefc71a2f1f909",
            "e19c14d0266740b4ae1b241bfc551b65",
            "e2dcccf4eb1240568e82591d8efa8bcf",
            "08042e9170eb4ae89a5eb9f0792614d6",
            "4624a9c9eaf54032ae8ea7c91a1eacfa",
            "ce769495021a46b986d7cc2447a1c34d",
            "d504097b278b44329acf9c3918d28ec6",
            "102bd80e283146feb48d9d22974cdb86",
            "7848f3c0170547a8a481a37ef8861877",
            "123a9e82a17440ac94926788e1958d00",
            "b6ab5ea410e1441daaf68ddf162fddc7",
            "e3591e86a41d4f3f8100cf38b000a24a",
            "b1374cb5195b40a890520cb9e0734c7c",
            "d9b0e2263f184c4281e35645adc0b7e5",
            "986b34344ce340a88c57b9276a4eaac0",
            "3a7644e32f124339ae404341f37cdef8",
            "e6057fb3a1c24056b6309043625b361f",
            "1115eca33e294981a3f778f13bcf0509",
            "0c378dbbfbb44aa592cbba1e23aec27c"
          ]
        },
        "id": "57d98c8c",
        "outputId": "097a3028-0305-41a0-d097-28e68b01384f"
      },
      "source": [
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_fn(example):\n",
        "    prompt = f\"{example['instruction']}\\n{example['input']}\"\n",
        "    labels = example['output']\n",
        "    text = f\"{prompt}\\n{labels}\"\n",
        "    tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=512)\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "tokenized_ds = dataset.map(tokenize_fn)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02336ce19a2b4fa18c03e7804e3df6b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de494844c63b4c7a81bc18750c650560"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "071e7073a8df4e858d8920ba0f3e40eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e20a93877fcf44aca8812aecdad1e33c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/810 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7848f3c0170547a8a481a37ef8861877"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cf3e0c9"
      },
      "source": [
        "## 6. Load Model with QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bdd8198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "644c2a9aeac346cbbed961afaa2fc262",
            "fed0d8d59f754357957814afbb23d870",
            "051ddee4e074411f9be502e5c3a53ffe",
            "40323cb1d7ca40faab5bc4d0dabe9612",
            "5a70f764c360489ca06c7f4073f54c99",
            "16fb77fc063d4de7a1322cf299aede9e",
            "fe6921864622468691d49112fb47b3d5",
            "285e3a06d2fe411faffdf689b6ab7af7",
            "aecdebf3860b4b1c94396e4bf814fcdb",
            "3c7744bd35fb43979a571fd5ce1b3a1b",
            "9ca7a28c21b4441cb31e436bdb0bce3b",
            "60e4ee8094ba4419bb09269272eb3fba",
            "d257a4c9c71044d99c690c7aa598dcc1",
            "f7e744e0af7f4f379073031f6a2ec630",
            "9ee043ffc58c49ee9c771a262bd5ab9b",
            "e9b3ebac8e4b47b383a8ade929058986",
            "63fb1ad1657140089f5b158110582809",
            "a3f99863714e4f4d94a7f38134de58c3",
            "dbba16501e9649b98505c426c1096c64",
            "29807330b05341bcac9db472c5922b79",
            "dc8fa16942b5485f857f59dbefa67b44",
            "43e94bdd1a09458e8a1467d03a64a4b8",
            "7c4e70960d804a5598bd473a15d23e75",
            "dde8ec39607e4319a0720b423f3b0083",
            "050e854e1a3c4a33906ea504828b1cc2",
            "f46c5b3615e845489c300811bde1e4f2",
            "1539377cbfbc492f83c7901e0a21c26b",
            "d6a4e8e6ba7a419d88463a3b326d3a40",
            "b63090f6ebb14f41ace92f010749fc80",
            "bf948328368c4d919ad25f2a8b5b55eb",
            "4f8b7e271cdc4981b08acd8a43b46374",
            "f46e8bdcd4c5441e895a7e1a75767639",
            "b455b3d9b2204eb5b92206e27bf078e7"
          ]
        },
        "outputId": "64aaee27-21f9-4428-ebaa-2068c136c79a"
      },
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    #load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\",\"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "644c2a9aeac346cbbed961afaa2fc262"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60e4ee8094ba4419bb09269272eb3fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c4e70960d804a5598bd473a15d23e75"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f79316c"
      },
      "source": [
        "## 7. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d6330c3a",
        "outputId": "8ac88eb4-9e17-4d9d-9cc3-1a3aa861d43a"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"tinyllama-slack\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ds\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahriar-arpon\u001b[0m (\u001b[33mshahriar-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250816_200149-putjui8j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shahriar-/huggingface/runs/putjui8j' target=\"_blank\">leafy-smoke-4</a></strong> to <a href='https://wandb.ai/shahriar-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shahriar-/huggingface' target=\"_blank\">https://wandb.ai/shahriar-/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shahriar-/huggingface/runs/putjui8j' target=\"_blank\">https://wandb.ai/shahriar-/huggingface/runs/putjui8j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [306/306 07:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>12.516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.794700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.236700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.151400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.096400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.057600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.016000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.016400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.016300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.016000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.015700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.015700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.015700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.015200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=306, training_loss=0.4988592133364257, metrics={'train_runtime': 844.8842, 'train_samples_per_second': 2.876, 'train_steps_per_second': 0.362, 'total_flos': 7739410627952640.0, 'train_loss': 0.4988592133364257, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "391f321a"
      },
      "source": [
        "## 8. Save LoRA Adapters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bb46fc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a171dedc-e32e-4fe4-92c6-5f24cbe1fa95"
      },
      "source": [
        "model.save_pretrained(\"tinyllama-slack-lora\")\n",
        "tokenizer.save_pretrained(\"tinyllama-slack-lora\")\n",
        "print(\"✅ Fine-tuning complete. Adapters saved to 'tinyllama-slack-lora'.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fine-tuning complete. Adapters saved to 'tinyllama-slack-lora'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fa6cbd2"
      },
      "source": [
        "## 9. Inference Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf503b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123924e2-330a-43ec-9bf6-dabdb54ad5be"
      },
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"tinyllama-slack-lora\")\n",
        "\n",
        "prompt = \"You are answering a question like a conversation.\\n Dana: We need to update the docs. \\nAlice:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(ft_model.device)\n",
        "outputs = ft_model.generate(**inputs, max_new_tokens=50)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are answering a question like a conversation.\n",
            " Dana: We need to update the docs. \n",
            "Alice:\n",
            "The API is returning a 200 status code.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bNIY2e0AU25"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}
